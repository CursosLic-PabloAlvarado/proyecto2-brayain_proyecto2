{"cells":[{"cell_type":"code","execution_count":1,"id":"80ceec42","metadata":{"id":"80ceec42","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686903745176,"user_tz":360,"elapsed":85153,"user":{"displayName":"Pedro Medinila Robles","userId":"07884454530791930208"}},"outputId":"c42a08a5-2372-412e-a8a1-059d5b602197"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gymnasium[atari]\n","  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (1.22.4)\n","Collecting jax-jumpy>=1.0.0 (from gymnasium[atari])\n","  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (4.5.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium[atari])\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[atari])\n","  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n","Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[atari])\n","  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[atari]) (5.12.0)\n","Installing collected packages: farama-notifications, jax-jumpy, ale-py, gymnasium, shimmy\n","Successfully installed ale-py-0.8.1 farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0 shimmy-0.2.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.28.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.22.4)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.0.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n","Collecting autorom[accept-rom-license]~=0.4.2 (from gymnasium[accept-rom-license])\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (8.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (4.65.0)\n","Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license])\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.4)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=093a7020a28e843f3e3567b9cef7643a75c36b26c493fbcd44f146c8623d7ce5\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom\n","Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Collecting gym\n","  Downloading gym-0.26.2.tar.gz (721 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ale-py in /usr/local/lib/python3.10/dist-packages (0.8.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py) (5.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py) (4.5.0)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827628 sha256=9c3f1b757f6f9dcfc99698372981d9181993ffe9c0eb52032dde39a6854961a0\n","  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n","Successfully built gym\n","Installing collected packages: gym\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gym-0.26.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keyboard\n","  Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keyboard\n","Successfully installed keyboard-0.13.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=a1f36a75b97cebc6d4c3477f73ebf5cfcabea1fce00ff94d6e984cc08066e669\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n","Num GPUs Available:  0\n"]}],"source":["!pip install gymnasium[atari]\n","!pip install gymnasium[accept-rom-license]\n","!pip install --upgrade gym ale-py\n","!pip install keyboard\n","!pip install keras\n","!pip install tensorflow\n","!pip install wandb\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from collections import deque\n","\n","\n","\n","from ale_py import ALEInterface\n","from ale_py.roms import SpaceInvaders\n","import pathlib\n","import gymnasium as gym\n","import wandb\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":null,"id":"c5a057ce","metadata":{"id":"c5a057ce"},"outputs":[],"source":["#Inicializar interfaz\n","ale = ALEInterface()\n"]},{"cell_type":"code","execution_count":null,"id":"c81a5020","metadata":{"id":"c81a5020"},"outputs":[],"source":["#cargar juego\n","ale.loadROM(SpaceInvaders)\n","\n","env = gym.make('ALE/SpaceInvaders-v5')\n","\n","n_inputs = env.observation_space.shape[0]\n","n_outputs = env.action_space.n\n"]},{"cell_type":"code","execution_count":null,"id":"03e8edaa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03e8edaa","executionInfo":{"status":"ok","timestamp":1686878943099,"user_tz":360,"elapsed":652,"user":{"displayName":"Pedro Medinila Robles","userId":"07884454530791930208"}},"outputId":"f95c46a5-0d9a-4a79-9759-b312c50ac103"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]}],"source":["main_nn = keras.Sequential([\n","    keras.layers.Conv2D(32, (8, 8), strides=4, activation='relu', input_shape=(210, 160, 3)),\n","    keras.layers.Conv2D(64, (4, 4), strides=2, activation='relu'),\n","    keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu'),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(512, activation='relu'),\n","    keras.layers.Dense(n_outputs)\n","])\n","\n","target_nn = keras.models.clone_model(main_nn)\n","\n","optimizer = keras.optimizers.Adam(lr=0.01)\n","loss_fn = keras.losses.mean_squared_error\n","\n","replay_buffer = deque(maxlen=10000)"]},{"cell_type":"code","execution_count":null,"id":"3475d220","metadata":{"id":"3475d220"},"outputs":[],"source":["def epsilon_greedy_policy(state, epsilon=0):\n","    if np.random.rand() < epsilon:\n","        return np.random.randint(n_outputs)\n","    else:\n","\n","        if isinstance(state, tuple) and len(state) == 2 and isinstance(state[0], np.ndarray) and isinstance(state[1], dict):\n","            Q_values = main_nn.predict(state[0][np.newaxis])\n","        else:\n","            Q_values = main_nn.predict(state[np.newaxis])\n","\n","        return np.argmax(Q_values[0])"]},{"cell_type":"code","execution_count":null,"id":"6710f901","metadata":{"id":"6710f901"},"outputs":[],"source":["def sample_experiences(batch_size):\n","    indices = np.random.randint(len(replay_buffer), size=batch_size)\n","    batch = [replay_buffer[index] for index in indices]\n","    states, actions, rewards, next_states, dones = [\n","        np.array([experience[field_index] for experience in batch], dtype=object)\n","        for field_index in range(5)]\n","    return states, actions, rewards, next_states, dones\n","\n"]},{"cell_type":"code","execution_count":null,"id":"7b7f5cbd","metadata":{"id":"7b7f5cbd"},"outputs":[],"source":["def play_one_step(env, state, epsilon):\n","    action = epsilon_greedy_policy(state, epsilon)\n","    result = env.step(action)\n","    next_state, reward, done, _,_ = env.step(action)\n","    if next_state.dtype == np.uint8:\n","        replay_buffer.append((state, action, reward, next_state, done))\n","    return next_state, reward\n"]},{"cell_type":"code","execution_count":null,"id":"9c3cc5d7","metadata":{"id":"9c3cc5d7"},"outputs":[],"source":["discount_rate = 0.99\n","\n","\n","def training_step(batch_size):\n","    experiences = sample_experiences(batch_size)\n","    states, actions, rewards, next_states, dones = experiences\n","    next_Q_values = target_nn.predict(next_states.astype('float32'))\n","    max_next_Q_values = np.max(next_Q_values, axis=1)\n","    target_Q_values = (rewards + (1 - dones) * discount_rate * max_next_Q_values)\n","    target_Q_values = target_Q_values.reshape(-1, 1)\n","    mask = tf.one_hot(actions.astype('int32'), n_outputs)\n","    with tf.GradientTape() as tape:\n","\n","        for i in range(len(states)):\n","            for state in states:\n","              print(state)\n","            if isinstance(states[i], tuple) and len(states[i]) == 2 and isinstance(states[i][0], np.ndarray) and isinstance(states[i][1], dict):\n","                states[i] = states[i][0]\n","            elif states[i].shape != (210, 160, 3):\n","                states[i] = states[i-1]\n","        #print(np.stack([np.array(state, dtype=object) for state in states]).astype('float32').shape)\n","        all_Q_values = main_nn(tf.convert_to_tensor(np.stack([np.array(state, dtype=object) for state in states]).astype('float32')))\n","        print(all_Q_values)\n","        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n","        loss = tf.reduce_mean(loss_fn(target_Q_values.astype('float32'), Q_values))\n","        print(loss)\n","    grads = tape.gradient(loss, main_nn.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, main_nn.trainable_variables))\n","\n","    return loss"]},{"cell_type":"code","source":["def play_one_step_train(env, state, model):\n","    # Verificar si el estado es una tupla\n","    if isinstance(state, tuple) and len(state) == 2 and isinstance(state[0], np.ndarray):\n","        state = state[0]\n","\n","    # Utilizar el modelo para predecir acciones\n","    Q_values = model.predict(state[np.newaxis])\n","    action = np.argmax(Q_values[0])\n","\n","    next_state, reward, done, _,_ = env.step(action)\n","    if next_state.dtype == np.uint8:\n","        replay_buffer.append((state, action, reward, next_state, done))\n","    return next_state, reward"],"metadata":{"id":"M9SJB4nifa1v"},"id":"M9SJB4nifa1v","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","# Mount Google Drive into Colab\n","drive.mount('/content/gdrive')\n","checkpoint_path = '/content/gdrive/My Drive/Proyecto 2 AA/SI/model_{episode:03d}.h5'\n","model_file = '/content/gdrive/My Drive/Proyecto 2 AA/SI/my_dqn.h5'"],"metadata":{"id":"UztMA1_vrjHP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686878944364,"user_tz":360,"elapsed":1268,"user":{"displayName":"Pedro Medinila Robles","userId":"07884454530791930208"}},"outputId":"a28c58fc-2499-48b3-e70f-650ffc3196a0"},"id":"UztMA1_vrjHP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","\n","wandb.init(project=\"SI Project\")\n","\n","\n","\n","# Create a ModelCheckpoint callback\n","checkpoint_callback = ModelCheckpoint(\n","    checkpoint_path,\n","    save_weights_only=True,\n","    save_best_only=False,\n","    save_freq=10,  # Save checkpoints every 10 episodes\n","    verbose=1\n",")\n","\n","# Add the checkpoint callback to the list of callbacks\n","callbacks = [checkpoint_callback]\n","start_episode = 0  # Set the starting episode\n","\n","# Check if any checkpoints exist\n","import glob\n","\n","directory = '/content/gdrive/My Drive/Proyecto 2 AA/SI/'\n","\n","# Get the list of checkpoint files in the directory\n","checkpoint_files = glob.glob(directory + 'model_*.h5')\n","\n","# Sort the checkpoint files by episode number\n","checkpoint_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n","\n","# Get the latest checkpoint file\n","latest_checkpoint = checkpoint_files[-1] if checkpoint_files else None\n","\n","print(f\"Latest checkpoint path: {latest_checkpoint}\")\n","\n","\n","if latest_checkpoint is not None:\n","    # Extract the episode number from the checkpoint path\n","    start_episode = int(latest_checkpoint.split('_')[1].split('.')[0])\n","\n","    # Load the weights from the latest checkpoint\n","    main_nn.load_weights(latest_checkpoint)\n","    print(f\"Resuming training from episode {start_episode }\")\n","else:\n","    print(\"No checkpoints found in the specified directory.\")\n","\n","print(f\"Latest checkpoint path: {latest_checkpoint}\")\n","\n"],"metadata":{"id":"gffXyYv1BOPM","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"2776a386-cf39-4c2d-cd35-66a288221601","executionInfo":{"status":"ok","timestamp":1686878952822,"user_tz":360,"elapsed":8464,"user":{"displayName":"Pedro Medinila Robles","userId":"07884454530791930208"}}},"id":"gffXyYv1BOPM","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:9gzyy1rz) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">dainty-donkey-31</strong> at: <a href='https://wandb.ai/loles/SI%20Project/runs/9gzyy1rz' target=\"_blank\">https://wandb.ai/loles/SI%20Project/runs/9gzyy1rz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230615_180840-9gzyy1rz/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:9gzyy1rz). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230615_192904-4lviwtff</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/loles/SI%20Project/runs/4lviwtff' target=\"_blank\">dainty-firebrand-32</a></strong> to <a href='https://wandb.ai/loles/SI%20Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/loles/SI%20Project' target=\"_blank\">https://wandb.ai/loles/SI%20Project</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/loles/SI%20Project/runs/4lviwtff' target=\"_blank\">https://wandb.ai/loles/SI%20Project/runs/4lviwtff</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Latest checkpoint path: /content/gdrive/My Drive/Proyecto 2 AA/SI/model_110.h5\n","Resuming training from episode 110\n","Latest checkpoint path: /content/gdrive/My Drive/Proyecto 2 AA/SI/model_110.h5\n"]}]},{"cell_type":"code","source":["\n","#LOOP\n","if os.path.isfile(model_file):\n","    model = keras.models.load_model(model_file)\n","\n","    env = gym.make('ALE/SpaceInvaders-v5', render_mode='human')\n","    obs = env.reset()\n","\n","    while True:\n","        obs, reward = play_one_step_train(env, obs, model)\n","\n","\n","else:\n","    for episode in range(start_episode, 600):\n","\n","        obs = env.reset()\n","\n","        for step in range(150):\n","            epsilon = max(1 - episode / 500, 0.01)\n","\n","            obs, reward = play_one_step(env, obs, epsilon)\n","\n","\n","            if episode > 70:\n","                loss = training_step(70)\n","\n","                wandb.log({\"episode\": episode, \"total_reward\": reward, \"loss\": loss})\n","        print(f\"Episode: {episode}\")\n","        if episode % 10 == 0:\n","            # Save the model every 10 episodes\n","            main_nn.save(checkpoint_path.format(episode=episode))\n","    main_nn.save('my_dqn.h5')"],"metadata":{"id":"Ela0rtSQ5irn"},"id":"Ela0rtSQ5irn","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}